{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6ccaa9cf-ad01-4787-a574-3bbac48a6452",
      "metadata": {
        "id": "6ccaa9cf-ad01-4787-a574-3bbac48a6452"
      },
      "source": [
        "# Project: The Meetings task manager extractor\n",
        "Welcome to your hands-on AI application build! Today, you aren't just writing code; you are building a tool that solves a common corporate headache: turning messy meeting minutes into assigned tasks.\n",
        "\n",
        "### üè¢ Our Company: TechStream Solutions\n",
        "We are a boutique software development company composed of a cross-functional team of 5 employees (IDs 0‚Äì4). To keep the gears turning, we rely on a diverse set of expertise:\n",
        "- Backend Developer\n",
        "- Customer Support\n",
        "- Data Scientist\n",
        "- HR Specialist\n",
        "- Marketing Specialist\n",
        "\n",
        "The core challenge in any cross-functional team is ensuring the right person gets the right task. Today, we will automate that decision-making process by developing a tool that:\n",
        "1. Extract tasks from meeting minutes\n",
        "2. Integrates a **machine learning model to automatically classify which employee should carry out a given task**.\n",
        "\n",
        "### üõ†Ô∏è The Workflow\n",
        "We will follow the professional Machine Learning pipeline to move from raw data to a functional product:\n",
        "\n",
        "**Data Exploration**: We'll dive into our historical dataset, which contains task descriptions, their corresponding task embeddings (numerical representations of text), and the employee best suited for that specific job.\n",
        "\n",
        "**Training & Comparison**: We will experiment with different \"Brains\" (Classifiers)‚Äîfrom Support Vector Machines (SVMs) and Random Forests to a custom Neural Network (MLP)‚Äîto see which one predicts assignments most accurately.\n",
        "\n",
        "**Deployment**: Your best model will be wrapped into a professional web application that runs directly in this notebook, allowing you to process meeting minutes in real-time.\n",
        "\n",
        "### üß† The Problem\n",
        "Our organization has a historical dataset of tasks linked to specific roles. Manually assigning these is slow and prone to human error. By the end of this project, you will have built an application that can \"read\" a new task and instantly predict which of our 5 employees should take the lead."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚öôÔ∏è Setup: install required packages and download project data { display-mode: \"form\" }\n",
        "#@markdown Running this cell will install the required packages and install the datasets we need for the project.\n",
        "#@markdown It might as you for authorization to connect to your ETH Google Drive to save the files.\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn torch\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def download_github_files(branch, folder_path, files):\n",
        "    \"\"\"\n",
        "    Downloads a list of files from a specific GitHub branch into a Drive folder.\n",
        "    \"\"\"\n",
        "    # Ensure the directory exists\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "        print(f\"‚úÖ Created directory: {folder_path}\")\n",
        "\n",
        "    base_url = f\"https://raw.githubusercontent.com/eth-bmai-fs26/project/refs/heads/{branch}/week1/task_meeting/data\"\n",
        "\n",
        "    for file_name in files:\n",
        "        url = f\"{base_url}/{file_name}\"\n",
        "        destination = os.path.join(folder_path, file_name)\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            if response.status_code == 200:\n",
        "                with open(destination, \"wb\") as f:\n",
        "                    f.write(response.content)\n",
        "                print(f\"üì• Successfully saved: {file_name}\")\n",
        "            else:\n",
        "                print(f\"‚ùå Failed to download {file_name} (Status: {response.status_code})\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error downloading {file_name}: {e}\")\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "BRANCH = \"main\"\n",
        "DATASET_FOLDER = \"/content/drive/MyDrive/BMAI/week1/task_meeting/data\"\n",
        "\n",
        "# List your 4 files here\n",
        "files_to_download = [\n",
        "    \"employee_tasks_hybrid.pkl\",\n",
        "    \"final_transcripts_meetings.csv\",\n",
        "    \"employee_tasks_meeting_id.pkl\"\n",
        "]\n",
        "\n",
        "# Run the download\n",
        "download_github_files(BRANCH, DATASET_FOLDER, files_to_download)"
      ],
      "metadata": {
        "id": "O0v0k9Jc9fIf"
      },
      "id": "O0v0k9Jc9fIf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4686e022-d883-4ca5-8321-c9c6b2ce61a4",
      "metadata": {
        "id": "4686e022-d883-4ca5-8321-c9c6b2ce61a4"
      },
      "source": [
        "## üìä Section 1: Data Exploration\n",
        "Before training our AI model, we first need to understand the data it will learn from. In our dataset, each row represents a real work task. It contains:\n",
        "\n",
        "*   Task Description: The actual text (e.g., \"Review the employment contracts\").\n",
        "*   Employee ID: The unique number for that role. This is the target label the model actually learns to predict.\n",
        "* Role: The job title or department (e.g., \"HR Specialist\"). This is the human-readable label.\n",
        "*   Task Embedding: The numerical representation of the task. (Think of this as the \"computer-readable\" version of the sentence). It's a list of numbers.\n",
        "\n",
        "\n",
        "üéØ Our goal is to train an AI system that can learn patterns from past tasks and make intelligent assignments in the future. But before training the model, we must check whether our data is fair, balanced, and meaningful.\n",
        "\n",
        "### ‚öñÔ∏è Data Balance Check\n",
        "\n",
        "How many tasks does each employee have? Are they equally represented?\n",
        "\n",
        "üí° Why this matters?\n",
        "\n",
        "If \"Employee A\" has 90% of the tasks, the AI may learn to assign most new tasks to \"Employee A\", simply because that was the most common pattern in the past.\n",
        "\n",
        "This means the AI would rely on historical frequency rather than truly understanding the task description. Therefore, we aim for a dataset where every employee has a similar number of tasks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset overview {display-mode: \"form\"}\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "df = pd.read_pickle(os.path.join(DATASET_FOLDER, 'employee_tasks_hybrid.pkl'))\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# üìä SECTION A: DATASET OVERVIEW\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Generate a Markdown table for Column Names & Types\n",
        "col_table = \"| Column Name | Data Type |\\n| :--- | :--- |\\n\"\n",
        "for col_name, dtype in df.dtypes.items():\n",
        "    actual_type = type(df[col_name].iloc[0]).__name__\n",
        "    col_table += f\"| **{col_name}** | `{actual_type}` |\\n\"\n",
        "\n",
        "# Create the main Overview String\n",
        "overview_text = f\"\"\"\n",
        "### üìä Dataset Overview\n",
        "| Metric | Value |\n",
        "| :--- | :--- |\n",
        "| **Total Rows (Tasks)** | {df.shape[0]} |\n",
        "| **Total Columns** | {df.shape[1]} |\n",
        "| **Missing Values** | {df.isnull().sum().sum()} |\n",
        "\n",
        "#### üìã Column Details:\n",
        "{col_table}\n",
        "\"\"\"\n",
        "\n",
        "# Render the Markdown\n",
        "display(Markdown(overview_text))\n",
        "\n",
        "sample_embedding = df['task_embedding'].iloc[0]\n",
        "embedding_dim = len(sample_embedding)\n",
        "\n",
        "embedding_peek = f\"\"\"\n",
        "#### üß† Embedding Inspection\n",
        "The model converts each task into a numerical vector (embedding).\n",
        "- **Dimensions:** `{embedding_dim}` (The size of the \"meaning\" space)\n",
        "- **First 5 values of a sample task:** `{list(sample_embedding[:5])}...`\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(embedding_peek))\n",
        "\n",
        "# We create a dictionary from the dataframe to map ID numbers back to Role names\n",
        "id_to_role = df.set_index('employee_id')['role'].to_dict()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# üî¢ SECTION B: TASKS PER EMPLOYEE (Array & Distribution)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 1. Get the counts\n",
        "employee_counts = df['employee_id'].value_counts()\n",
        "\n",
        "# Create a clean plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "employee_counts.plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
        "\n",
        "ax.set_title(f\"Task Distribution per Employee (Balance Check)\", fontsize=14)\n",
        "ax.set_ylabel(\"Number of Tasks\")\n",
        "ax.set_xlabel(\"Employee ID\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Add value labels on top of bars\n",
        "for i, v in enumerate(employee_counts):\n",
        "    ax.text(i, v + 0.5, str(v), ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Final Imbalance Check\n",
        "imbalance_ratio = employee_counts.max() / employee_counts.min()\n",
        "print(f\"‚öñÔ∏è Imbalance Ratio: {imbalance_ratio:.2f} (1.00 is perfect balance)\")\n",
        "\n",
        "print(\"=== Task Description Analysis ===\")\n",
        "\n",
        "if 'task_description' in df.columns:\n",
        "    # Text length distribution\n",
        "    df['text_length'] = df['task_description'].str.len()\n",
        "    df['word_count'] = df['task_description'].str.split().str.len()\n",
        "\n",
        "    print(f\"Text length stats:\\n{df['text_length'].describe()}\")\n",
        "    print(f\"\\nWord count stats:\\n{df['word_count'].describe()}\")\n",
        "\n",
        "    # Sample tasks per role\n",
        "    print(\"\\n=== Sample Tasks per Role ===\")\n",
        "    if 'role' in df.columns:\n",
        "        for role in df['role'].unique()[:5]:\n",
        "            print(f\"\\n--- {role} ---\")\n",
        "            samples = df[df['role'] == role]['task_description'].head(3).tolist()\n",
        "            for s in samples:\n",
        "                print(f\"  ‚Ä¢ {s[:100]}...\")"
      ],
      "metadata": {
        "id": "xSh7ZzKFCVmN"
      },
      "id": "xSh7ZzKFCVmN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üéØ Section 1.1 - YOUR TASK - Dataset Knowledge Check (reply to the questions and then run the cell) { display-mode: \"form\" }\n",
        "\n",
        "#@markdown **Question 1:** Based on the bar chart above, how many tasks does the employee with ID 0 have?\n",
        "ans_tasks_id0 = 0 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown **Question 2:** What is the dimension of the task embedding (i.e. how many \"numbers\" are there in each embedding)? (Hint: Check the 'Embedding Inspection' section)\n",
        "ans_dimensions = 0 #@param {type:\"integer\"}\n",
        "\n",
        "def check_answers():\n",
        "    # Validation logic using the variables already in your memory\n",
        "    correct_tasks = 350\n",
        "    correct_dims = 384\n",
        "\n",
        "    results = []\n",
        "\n",
        "    if ans_tasks_id0 == correct_tasks:\n",
        "        results.append(\"‚úÖ Q1: Correct! Employee 0 is staying busy.\")\n",
        "    else:\n",
        "        results.append(f\"‚ùå Q1: Not quite. Take another look at the bar for ID 0.\")\n",
        "\n",
        "    if ans_dimensions == correct_dims:\n",
        "        results.append(f\"‚úÖ Q2: Perfect! Each task is a vector of {correct_dims} numbers.\")\n",
        "    else:\n",
        "        results.append(f\"‚ùå Q2: Try again. Look at the length of the embedding array.\")\n",
        "\n",
        "    print(\"\\n\".join(results))\n",
        "\n",
        "# Run the check\n",
        "check_answers()"
      ],
      "metadata": {
        "id": "q2PN4fNEEwYS"
      },
      "id": "q2PN4fNEEwYS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üí° Note: How can the AI understand task descriptions?\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "The answer is embeddings.\n",
        "\n",
        "Embeddings convert each task description into a list of numbers that capture its meaning, not just its appearance.\n",
        "\n",
        "This allows the AI model to recognize patterns and relationships between tasks based on their content.\n",
        "\n",
        "Importantly, because embeddings capture meaning and context, the AI does not rely on simplistic rules, such as:\n",
        "\n",
        "* assigning tasks based only on the length of the description\n",
        "* matching specific keywords to specific employees\n",
        "\n",
        "Instead, the AI learns to interpret the overall meaning of the task, which leads to more accurate and reliable predictions!"
      ],
      "metadata": {
        "id": "_NcgQ0SkJGzG"
      },
      "id": "_NcgQ0SkJGzG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Section 1.2 - YOUR TASK - Data Preparation\n",
        "Now we prepare the data for machine learning:\n",
        "1. Define features ($X$) and target ($y$)\n",
        "    * Input ($X$): The task_embedding (the numerical \"meaning\" of the task).\n",
        "\n",
        "    * Target ($y$): The employee_id (values 0‚Äì4). Since these are already numbers‚Äîand therefore understandable by computers‚Äîwe can use them directly.\n",
        "\n",
        "2. Split into Train/Test Sets\n",
        "    * We divide the data so we have one set to teach the model (Train) and a separate hidden set to evaluate it later (Test)."
      ],
      "metadata": {
        "id": "irYOqrlcJMWh"
      },
      "id": "irYOqrlcJMWh"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Define Features (X) and Target (y)\n",
        "# We stack the embedding lists into a matrix (Rows=Tasks, Cols=Dimensions)\n",
        "X = np.vstack(df['task_embedding'].values)\n",
        "y = df['employee_id']  # Already 0-4, so no encoding needed\n",
        "\n",
        "# 2. Split into Train/Test Sets\n",
        "# üéØüéØüéØ - TODO üéØüéØüéØ\n",
        "# Call the train_test_split function that we imported from scikit-learn\n",
        "X_train, X_test, y_train, y_test = ...\n",
        "\n",
        "# We numpy to find the unique labels and count them\n",
        "unique_classes, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "print(f\"‚úÖ Data Prepared Successfully!\")\n",
        "print(f\"Training on {len(X_train)} tasks.\")\n",
        "print(f\"Testing on {len(X_test)} tasks.\")\n",
        "\n",
        "print(\"\\n--- Samples per Class ---\")\n",
        "for cls, count in zip(unique_classes, counts):\n",
        "    print(f\"Class {cls}: {count} tasks\")"
      ],
      "metadata": {
        "id": "ePWyhqbLJQ-m"
      },
      "id": "ePWyhqbLJQ-m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the \"Map of Meaning\"\n",
        "\n",
        "The image below presents a 2D visualization of complex task data, generated using **Principal Component Analysis (PCA)**.\n",
        "\n",
        "Our original task embeddings exist in a high-dimensional space (384 dimensions) that humans cannot visualize. PCA is a dimensionality reduction technique that acts like a \"summarizer.\" It finds the two \"directions\" (Principal Components) along which the data varies the most and flattens the high-dimensional map onto this 2D plane. The resulting scatterplot shows how the AI perceives the relationship between different tasks based on their abstract meaning. Points that are closer together are seen by the AI as semantically similar.\n",
        "\n",
        "**ü§î A (maybe) thought-provoking question:**\n",
        "Look closely at the distinct clusters formed by the different shapes and colors. While some groups (like the dark blue 'x' marks at the bottom) are relatively isolated, others (like the purple circles and green '+' signs on the right) show significant overlap. If these clusters represent tasks typically done by different roles, what does that overlap imply about the boundaries of those roles in a real-world working environment?"
      ],
      "metadata": {
        "id": "jag5QZeWJg9x"
      },
      "id": "jag5QZeWJg9x"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize the data in PCA { display-mode: \"form\" }\n",
        "# ============================================================\n",
        "#\n",
        "# We use PCA (Principal Component Analysis) to squash the\n",
        "# 384-dimensional vectors down to 2D so we can draw them.\n",
        "# ============================================================\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Squash the data to 2 Dimensions (2D)\n",
        "pca = PCA(n_components=2)\n",
        "X_embedded_2d = pca.fit_transform(X_test)\n",
        "\n",
        "# 2. Create a temporary DataFrame for plotting\n",
        "# We use the 'id_to_role' dictionary to get the actual names\n",
        "role_names = [id_to_role[i] for i in y_test]\n",
        "\n",
        "df_viz = pd.DataFrame(X_embedded_2d, columns=['Dimension 1', 'Dimension 2'])\n",
        "df_viz['Role'] = role_names\n",
        "\n",
        "# 3. Plot the clusters\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(\n",
        "    data=df_viz,\n",
        "    x='Dimension 1',\n",
        "    y='Dimension 2',\n",
        "    hue='Role',      # Color points by Role\n",
        "    style='Role',    # Different shapes for different roles\n",
        "    s=100,           # Size of dots\n",
        "    alpha=0.8,       # Transparency\n",
        "    palette='viridis'\n",
        ")\n",
        "\n",
        "plt.title('The \"Map of Meaning\": How the AI Sees the Tasks', fontsize=16)\n",
        "plt.xlabel('Abstract Meaning (Dimension 1)')\n",
        "plt.ylabel('Abstract Meaning (Dimension 2)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Employee Role\")\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_iGMCk4QJhlh"
      },
      "id": "_iGMCk4QJhlh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e78e2ac7-6cff-4f37-8baf-ba11e77aa2dc",
      "metadata": {
        "id": "e78e2ac7-6cff-4f37-8baf-ba11e77aa2dc"
      },
      "source": [
        "## üß† Section 2: Now we train our model!\n",
        "\n",
        "We will now use the emb column as our input ($X$) and the emp_id as our target ($y$).\n",
        "Neural Networks are powerful but can \"overfit\" (memorize) small datasets. SVMs are more robust for smaller samples. Maybe Random forests are better. Which one performs better on our test data?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5b00891-ae6c-4020-b832-f0d12ebfe872",
      "metadata": {
        "id": "f5b00891-ae6c-4020-b832-f0d12ebfe872"
      },
      "source": [
        "## üéØ Section 2.1 - YOUR TASK - Try using SVMs?\n",
        "\n",
        "### What is an SVM\n",
        " ---------------\n",
        " Imagine you have a bunch of colored dots floating in space.\n",
        " An SVM (Support Vector Machine) draws the BEST possible line (or sheet) to separate the colors.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        " For example, if you have green diamonds (Backend Developers) and blue dots\n",
        " (HR Specialists), the SVM finds where to draw a line so that all\n",
        " green diamonds are on one side and blue dots on the other.\n",
        "\n",
        " ### What is a kernel\n",
        "-------------------\n",
        " A kernel is the \"shape\" of the boundary the SVM draws:\n",
        " - LINEAR kernel = straight line (or flat plane in our embedding space)\n",
        " - RBF kernel = curved/wavy line (we'll try this next)\n",
        "\n",
        " ### What is the $C$ parameter?\n",
        " --------------------------\n",
        " $C$ controls how strict the SVM is:\n",
        " - Low $C$ (e.g., 0.1): Draws a simpler line, okay with some mistakes\n",
        " - High $C$ (e.g., 10): Tries VERY hard to get every point right\n",
        " - $C=1$: A balanced middle ground (what we use here)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utils for the report {display-mode: \"form\"}\n",
        "def print_report(y_test, y_pred, id_to_role):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nüìä RESULTS: Linear SVM\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)\")\n",
        "\n",
        "    # Get the list of role names in the correct order (0, 1, 2, 3...)\n",
        "    # We use the 'id_to_role' dictionary created in the Data Prep step\n",
        "    target_names = [id_to_role[i] for i in sorted(id_to_role.keys())]\n",
        "\n",
        "    # Classification report shows detailed stats for each role:\n",
        "    # - Precision: When it predicts \"Doctor\", how often is it right?\n",
        "    # - Recall: Out of all actual Doctors, how many did it find?\n",
        "    print(f\"\\nDetailed Metrics per Role:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "    # --- STEP 5: Visualize with a confusion matrix ---\n",
        "    # A confusion matrix shows WHERE the model makes mistakes:\n",
        "    # - Rows = what the task ACTUALLY is\n",
        "    # - Columns = what the model PREDICTED\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=target_names,\n",
        "                yticklabels=target_names)\n",
        "\n",
        "    plt.title('Confusion Matrix: SVM (Linear Kernel)')\n",
        "    plt.xlabel('What the model PREDICTED')\n",
        "    plt.ylabel('What it ACTUALLY was')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Warn if accuracy is suspiciously high\n",
        "    if accuracy > 0.99:\n",
        "        print(\"\\n‚ö†Ô∏è NOTE: Accuracy > 99% is very high!\")\n",
        "        print(\"   This is expected here because Embeddings capture MEANING.\")\n",
        "        print(\"   The model can easily separate 'Medical' concepts from 'IT' concepts\")\n",
        "        print(\"   because they live in different parts of the vector space.\")"
      ],
      "metadata": {
        "id": "5m7AnG2bIYc3"
      },
      "id": "5m7AnG2bIYc3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SUPPORT VECTOR MACHINE (SVM) - LINEAR KERNEL\n",
        "# ============================================================\n",
        "\n",
        "from sklearn.svm import SVC  # SVC = Support Vector Classifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# --- STEP 1: Create the model ---\n",
        "# We're telling Python: \"I want an SVM with a straight-line boundary\"\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Instantiate a SVM using the SVC class from scikit-learn.\n",
        "# Use a linear kernel, use C=1.0, and a random state of 42.\n",
        "svm_linear = ...\n",
        "\n",
        "# --- STEP 2: Train the model ---\n",
        "# \"Training\" = showing the model many examples so it learns the pattern.\n",
        "# X_train contains the TASK EMBEDDINGS (numerical meaning of the text).\n",
        "# y_train contains the correct answers (employee IDs).\n",
        "print(\"üèãÔ∏è Training SVM with Linear Kernel...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Call the fit method on the svm_linear variable to make the learning happen.\n",
        "# Should you use the training dataset, the test dataset, or both?\n",
        "...\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"‚úÖ Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "# --- STEP 3: Make predictions on test data ---\n",
        "# Now we test: can the model correctly classify tasks it has NEVER seen?\n",
        "# X_test contains new task embeddings the model wasn't trained on.\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Call the predict method on the svm_linear variable to predict the employee IDs\n",
        "# using the previously trained model.\n",
        "# Should you use the training dataset, the test dataset, or both?\n",
        "y_pred_linear = ...\n",
        "\n",
        "# --- STEP 4: Evaluate performance ---\n",
        "print_report(y_test, y_pred_linear, id_to_role)"
      ],
      "metadata": {
        "id": "bfuX3VrcKXB_"
      },
      "id": "bfuX3VrcKXB_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a30daecd-8c21-4131-925f-591b055c8bcd",
      "metadata": {
        "id": "a30daecd-8c21-4131-925f-591b055c8bcd"
      },
      "source": [
        "## üéØ Section 2.2 - YOUR TASK - Try using Random Forests?\n",
        "### WHAT IS A RANDOM FOREST?\n",
        " ------------------------\n",
        " Imagine asking 100 different people to guess something.\n",
        " Each person might make mistakes, but if you take the MAJORITY vote,\n",
        " you'll usually get the right answer!\n",
        "\n",
        " That's exactly what a Random Forest does:\n",
        " 1. It creates many \"Decision Trees\" (like 100 different voters)\n",
        " 2. Each tree makes its own prediction\n",
        " 3. The final answer = whatever most trees agree on\n",
        "\n",
        "### WHAT IS A DECISION TREE?\n",
        " ------------------------\n",
        " A decision tree is like a game of \"20 Questions\":\n",
        " - \"Does the task mention 'prescribe'?\" ‚Üí If yes, probably Doctor\n",
        " - \"Does the task mention 'dispense'?\" ‚Üí If yes, probably Pharmacist\n",
        "\n",
        " (Note: Since we are using Embeddings, the tree actually asks questions\n",
        "  about the numerical values, like \"Is dimension 5 > 0.2?\", but the\n",
        "  logic is exactly the same!)\n",
        "\n",
        "### KEY PARAMETERS:\n",
        "---------------\n",
        " - `n_estimators`: How many trees to create (more = usually better, but slower)\n",
        " - `max_depth`: How many questions each tree can ask (None = unlimited)\n",
        " - `random_state`: Makes results reproducible"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# RANDOM FOREST CLASSIFIER\n",
        "# ============================================================\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# --- STEP 1: Create the model ---\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Instantiate a Random Forest using the RandomForestClassifier class from scikit-learn.\n",
        "# Use 100 estimators, and no max_depth.\n",
        "# Afterwards, experiment with different hyperparameters :)\n",
        "rf_model = ...\n",
        "\n",
        "# --- STEP 2: Train the model ---\n",
        "print(\"üå≤ Training Random Forest (100 trees)...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Call the fit method on the svm_linear variable to make the learning happen.\n",
        "# Should you use the training dataset, the test dataset, or both?\n",
        "...\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"‚úÖ Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "# --- STEP 3: Make predictions ---\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Call the predict method on the svm_linear variable to predict the employee IDs\n",
        "# using the previously trained model.\n",
        "# Should you use the training dataset, the test dataset, or both?\n",
        "y_pred_rf = ...\n",
        "\n",
        "# --- STEP 4: Evaluate performance ---\n",
        "print_report(y_test, y_pred_rf, id_to_role)"
      ],
      "metadata": {
        "id": "2K2zJB2ZLtqT"
      },
      "id": "2K2zJB2ZLtqT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0869a67d-ba6a-4794-af44-0994af05e447",
      "metadata": {
        "id": "0869a67d-ba6a-4794-af44-0994af05e447"
      },
      "source": [
        "## üéØ Section 2.3 - YOUR TASK - Try using Neural Networks?\n",
        " For the Neural Network, we will be using PyTorch. PyTorch is one of the most popular libraries for building neural networks, used by researchers and companies like Meta, Tesla, and OpenAI. It gives us a lot of control over the final network.\n",
        "\n",
        "### WHAT'S DIFFERENT FROM SCIKIT-LEARN?\n",
        "-----------------------------------\n",
        " With scikit-learn (SVM, Random Forest), we just called `.fit()` and `.predict()`.\n",
        " With PyTorch, we have more control but also more steps:\n",
        "\n",
        "   1. Prepare data in a special format (Tensors & DataLoaders)\n",
        "   2. Define the neural network architecture (how many layers, etc.)\n",
        "   3. Write a training loop (show data to network many times)\n",
        "   4. Evaluate on test data\n",
        "\n",
        " Don't worry - we'll go through each step carefully!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# NEURAL NETWORKS WITH PYTORCH - PART 1: UNDERSTANDING THE BASICS\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn  # nn = \"neural network\" module\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Check if we have a GPU available (makes training faster)\n",
        "# Don't worry if you don't have one - CPU works fine for this example!\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üñ•Ô∏è Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"   (No GPU detected - using CPU, which is fine for this dataset!)\")"
      ],
      "metadata": {
        "id": "GIjxjC7IMFKj"
      },
      "id": "GIjxjC7IMFKj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np # Ensure numpy is imported\n",
        "\n",
        "# ============================================================\n",
        "# PART 2: CONVERTING DATA TO PYTORCH FORMAT (Tensors)\n",
        "# ============================================================\n",
        "#\n",
        "# WHAT IS A TENSOR?\n",
        "# -----------------\n",
        "# A tensor is just a fancy word for \"a box of numbers\" that\n",
        "# PyTorch can process very efficiently on a GPU/CPU.\n",
        "#\n",
        "# Examples:\n",
        "#   - A single number (like 5) is a 0D tensor (scalar)\n",
        "#   - A list [1, 2, 3] is a 1D tensor (vector)\n",
        "#   - A table/grid is a 2D tensor (matrix)\n",
        "#\n",
        "# WHY DO WE NEED THIS?\n",
        "# --------------------\n",
        "# PyTorch models cannot read numpy arrays or pandas columns directly.\n",
        "# We must convert our data into PyTorch's native format.\n",
        "#\n",
        "# ============================================================\n",
        "\n",
        "# Step 1: Convert numpy arrays/pandas series to PyTorch tensors\n",
        "\n",
        "# For inputs (X), we use float32 (standard for neural networks)\n",
        "# X_train is likely already a numpy array from the split step\n",
        "# For labels (y), we use torch.long because they are integers (0, 1, 2...)\n",
        "# ‚ö†Ô∏è FIX: We add .values to convert the Pandas Series to a Numpy Array first!\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Create two tensors for the test data\n",
        "X_test_tensor = ...\n",
        "y_test_tensor = ...\n",
        "\n",
        "print(f\"‚úÖ Converted to PyTorch tensors\")\n",
        "print(f\"   X_train_tensor shape: {X_train_tensor.shape}\")\n",
        "print(f\"   y_train_tensor shape: {y_train_tensor.shape}\")\n",
        "\n",
        "# Quick sanity check: how many features and classes do we have?\n",
        "num_features = X_train_tensor.shape[1]  # The size of the embedding (should be 384)\n",
        "num_classes = len(id_to_role)           # Number of unique roles (employees)\n",
        "\n",
        "print(f\"\\nüìä Summary:\")\n",
        "print(f\"   Input Size (Embedding Dimensions): {num_features}\")\n",
        "print(f\"   Output Size (Number of Classes):   {num_classes}\")"
      ],
      "metadata": {
        "id": "Lwwr71zzMHw3"
      },
      "id": "Lwwr71zzMHw3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PART 3: CREATING A DATASET AND DATALOADER\n",
        "# ============================================================\n",
        "#\n",
        "# WHAT IS A DATASET?\n",
        "# ------------------\n",
        "# A Dataset is a container that holds your data and knows how to\n",
        "# give you one sample at a time. Think of it like a filing cabinet\n",
        "# where each drawer contains one example.\n",
        "#\n",
        "# WHAT IS A DATALOADER?\n",
        "# ---------------------\n",
        "# A DataLoader takes samples from the Dataset and groups them into\n",
        "# \"batches\". Instead of training on one example at a time (slow!),\n",
        "# we train on a batch of examples together (faster!).\n",
        "#\n",
        "# Example: If you have 400 training examples and batch_size=32,\n",
        "# the DataLoader will give you 13 batches of 32 examples each.\n",
        "#\n",
        "# WHY BATCHES?\n",
        "# ------------\n",
        "# 1. Faster training (parallel processing)\n",
        "# 2. More stable learning (averages out noise from individual examples)\n",
        "# 3. Uses less memory than loading everything at once\n",
        "#\n",
        "# ============================================================\n",
        "\n",
        "# Create a simple Dataset class\n",
        "# This tells PyTorch how to access our data\n",
        "class TaskDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A custom Dataset for our task classification problem.\n",
        "\n",
        "    Required methods:\n",
        "    - __init__: Set up the data\n",
        "    - __len__: Return the total number of samples\n",
        "    - __getitem__: Return one sample given an index\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, features, labels):\n",
        "        \"\"\"\n",
        "        Store our features (X) and labels (y).\n",
        "\n",
        "        Args:\n",
        "            features: The TF-IDF features (as a tensor)\n",
        "            labels: The role labels (as a tensor)\n",
        "        \"\"\"\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return how many samples we have.\"\"\"\n",
        "        # üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "        # Return the number of samples (e.g. labels) in the dataset.\n",
        "        # Hint: you can use the `len` function on a tensor\n",
        "        return ...\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Return one sample.\n",
        "\n",
        "        Args:\n",
        "            idx: Which sample to return (0, 1, 2, ...)\n",
        "\n",
        "        Returns:\n",
        "            A tuple of (features, label) for that sample\n",
        "        \"\"\"\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "# Create Dataset objects\n",
        "train_dataset = TaskDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TaskDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "print(f\"‚úÖ Created Datasets\")\n",
        "print(f\"   Training samples: {len(train_dataset)}\")\n",
        "print(f\"   Test samples: {len(test_dataset)}\")\n",
        "\n",
        "# Create DataLoaders\n",
        "# batch_size=32 is a common choice - not too small, not too big\n",
        "# shuffle=True for training (mix up the order each time)\n",
        "# shuffle=False for testing (we want consistent results)\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Experiment with different batch sizes!\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Create the train data and test data DataLoader s\n",
        "train_loader = ...\n",
        "test_loader = ...\n",
        "\n",
        "print(f\"\\n‚úÖ Created DataLoaders with batch_size={BATCH_SIZE}\")\n",
        "print(f\"   Training batches: {len(train_loader)}\")\n",
        "print(f\"   Test batches: {len(test_loader)}\")\n",
        "\n",
        "# Let's look at one batch to understand the shape\n",
        "sample_features, sample_labels = next(iter(train_loader))\n",
        "print(f\"\\nüì¶ One batch looks like:\")\n",
        "print(f\"   Features shape: {sample_features.shape}  (batch_size x num_features)\")\n",
        "print(f\"   Labels shape: {sample_labels.shape}  (batch_size,)\")"
      ],
      "metadata": {
        "id": "6ofkXSfsMKb2"
      },
      "id": "6ofkXSfsMKb2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PART 4: BUILDING THE NEURAL NETWORK (MLP)\n",
        "# ============================================================\n",
        "#\n",
        "# WHAT IS AN MLP?\n",
        "# ---------------\n",
        "# MLP = Multi-Layer Perceptron (don't worry about the fancy name!)\n",
        "#\n",
        "# It's the simplest type of neural network:\n",
        "#   Input ‚Üí Hidden Layer(s) ‚Üí Output\n",
        "#\n",
        "# Think of it like a series of transformations:\n",
        "#   1. Take the input (text embeddings)\n",
        "#   2. Transform it through hidden layers (learn patterns)\n",
        "#   3. Output a prediction (which role?)\n",
        "#\n",
        "# WHAT'S A \"LAYER\"?\n",
        "# -----------------\n",
        "# A layer is a group of \"neurons\" that process data.\n",
        "# Each layer transforms the data in some way.\n",
        "#\n",
        "# Example architecture for our problem:\n",
        "#   Input (328 dimensions) ‚Üí Hidden (128 neurons) ‚Üí Hidden (64 neurons) ‚Üí Output (5 classes)\n",
        "#\n",
        "# WHAT'S AN \"ACTIVATION FUNCTION\"?\n",
        "# --------------------------------\n",
        "# After each layer, we apply an activation function.\n",
        "# It adds \"non-linearity\" - without it, the network would just be\n",
        "# a fancy linear equation (no better than a straight line).\n",
        "#\n",
        "# We'll use ReLU (Rectified Linear Unit):\n",
        "#   - If input > 0: output = input\n",
        "#   - If input ‚â§ 0: output = 0\n",
        "# Simple but effective!\n",
        "#\n",
        "# ============================================================\n",
        "\n",
        "class SimpleMLP(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple Multi-Layer Perceptron for text classification.\n",
        "\n",
        "    Architecture:\n",
        "        Input ‚Üí Linear ‚Üí ReLU ‚Üí Linear ‚Üí ReLU ‚Üí Linear ‚Üí Output\n",
        "\n",
        "    This is a 3-layer network (2 hidden layers + 1 output layer).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
        "        \"\"\"\n",
        "        Set up the layers of the network.\n",
        "\n",
        "        Args:\n",
        "            input_size: Number of input features (5000 TF-IDF features)\n",
        "            hidden_size1: Number of neurons in first hidden layer\n",
        "            hidden_size2: Number of neurons in second hidden layer\n",
        "            num_classes: Number of output classes (roles to predict)\n",
        "        \"\"\"\n",
        "        super(SimpleMLP, self).__init__()  # Required boilerplate\n",
        "\n",
        "        # Define the layers\n",
        "        # nn.Linear = a fully connected layer (every input connects to every output)\n",
        "        # üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "        # Create three linear layers\n",
        "        self.layer1 = ...   # Input ‚Üí Hidden1\n",
        "        self.layer2 = ... # Hidden1 ‚Üí Hidden2\n",
        "        self.layer3 = ...  # Hidden2 ‚Üí Output\n",
        "\n",
        "        # Activation function (applied after each layer except the last)\n",
        "        # üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "        # Connect the correct ReLU function\n",
        "        self.relu = ...\n",
        "\n",
        "        # Dropout: randomly \"turns off\" some neurons during training\n",
        "        # This prevents overfitting (memorizing instead of learning)\n",
        "        # 0.5 = 50% of neurons are randomly turned off each time\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define how data flows through the network.\n",
        "\n",
        "        This is called automatically when you do: model(input)\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch_size, input_size)\n",
        "\n",
        "        Returns:\n",
        "            Output tensor of shape (batch_size, num_classes)\n",
        "        \"\"\"\n",
        "        # Layer 1: Linear ‚Üí ReLU ‚Üí Dropout\n",
        "        x = self.layer1(x)      # Transform the input\n",
        "        x = self.relu(x)        # Apply activation\n",
        "        x = self.dropout(x)     # Apply dropout\n",
        "\n",
        "        # Layer 2: Linear ‚Üí ReLU ‚Üí Dropout\n",
        "        # üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "        # Create the second layer: linear and ReLU\n",
        "        # Optionally, you can add dropout at the end.\n",
        "        x = ...\n",
        "\n",
        "        # Layer 3: Linear (no activation - we'll apply softmax later)\n",
        "        # üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "        # Create the third layer: just a linear layer\n",
        "        x = ...\n",
        "\n",
        "        return x\n",
        "\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Instantiate the model you have just created by setting these\n",
        "# hyperparameters values.\n",
        "HIDDEN_SIZE_1 = ...\n",
        "HIDDEN_SIZE_2 = ...\n",
        "NUM_CLASSES = ...\n",
        "nn_model = SimpleMLP(\n",
        "    input_size=num_features,    # 5000 TF-IDF features\n",
        "    hidden_size1=HIDDEN_SIZE_1,           # First hidden layer: 128 neurons\n",
        "    hidden_size2=HIDDEN_SIZE_2,            # Second hidden layer: 64 neurons\n",
        "    num_classes=NUM_CLASSES     # Output: one score per role\n",
        ")\n",
        "\n",
        "# Move model to GPU if available\n",
        "nn_model = nn_model.to(device)\n",
        "\n",
        "# Let's see what our model looks like!\n",
        "print(\"üß† MODEL ARCHITECTURE:\")\n",
        "print(\"=\" * 50)\n",
        "print(nn_model)\n",
        "print()\n",
        "\n",
        "# Count the number of parameters (weights the model will learn)\n",
        "total_params = sum(p.numel() for p in nn_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in nn_model.parameters() if p.requires_grad)\n",
        "print(f\"üìä Total parameters: {total_params:,}\")\n",
        "print(f\"   Trainable parameters: {trainable_params:,}\")"
      ],
      "metadata": {
        "id": "pP1iE0jbMM_c"
      },
      "id": "pP1iE0jbMM_c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PART 5: SETTING UP TRAINING (Loss Function & Optimizer)\n",
        "# ============================================================\n",
        "#\n",
        "# To train a neural network, we need two things:\n",
        "#\n",
        "# 1. LOSS FUNCTION (also called \"criterion\")\n",
        "#    ----------------------------------------\n",
        "#    This measures \"how wrong\" the model's predictions are.\n",
        "#\n",
        "#    For classification, we use \"Cross-Entropy Loss\":\n",
        "#    - If the model is confident AND correct ‚Üí low loss\n",
        "#    - If the model is confident AND wrong ‚Üí high loss\n",
        "#    - If the model is uncertain ‚Üí medium loss\n",
        "#\n",
        "#    The goal of training is to MINIMIZE the loss.\n",
        "#\n",
        "# 2. OPTIMIZER\n",
        "#    ---------\n",
        "#    This decides HOW to update the model's weights to reduce the loss.\n",
        "#\n",
        "#    We use \"Adam\" optimizer - it's like a smart version of gradient descent:\n",
        "#    - Automatically adjusts how fast to learn for each parameter\n",
        "#    - Works well out-of-the-box (no manual tuning needed)\n",
        "#\n",
        "#    \"Learning rate\" = how big of a step to take when updating weights\n",
        "#    - Too high: Model overshoots and never converges\n",
        "#    - Too low: Training takes forever\n",
        "#    - 0.001 is a good default starting point\n",
        "#\n",
        "# ============================================================\n",
        "\n",
        "# Loss function for multi-class classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer: Adam with learning rate 0.001\n",
        "# model.parameters() tells Adam which values to update\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Choose a sensible learning rate [range: 0.000001 - 0.1]\n",
        "learning_rate = ...\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# create an optimizer by calling torch.optim.Adam\n",
        "optimizer = ...\n",
        "\n",
        "print(\"‚úÖ Training setup complete!\")\n",
        "print(f\"   Loss function: CrossEntropyLoss\")\n",
        "print(f\"   Optimizer: Adam\")\n",
        "print(f\"   Learning rate: {learning_rate}\")"
      ],
      "metadata": {
        "id": "DfEcNtgiMPQB"
      },
      "id": "DfEcNtgiMPQB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PART 6: THE TRAINING LOOP\n",
        "# ============================================================\n",
        "#\n",
        "# Training a neural network is an iterative process:\n",
        "#\n",
        "# For each EPOCH (one pass through all training data):\n",
        "#     For each BATCH of data:\n",
        "#         1. Forward pass: Get predictions from the model\n",
        "#         2. Calculate loss: How wrong were we?\n",
        "#         3. Backward pass: Calculate gradients (which direction to update)\n",
        "#         4. Update weights: Adjust model parameters to reduce loss\n",
        "#\n",
        "# WHAT'S AN EPOCH?\n",
        "# ----------------\n",
        "# One epoch = showing the model ALL training examples once.\n",
        "# We usually need multiple epochs because the model improves gradually.\n",
        "#\n",
        "# Think of it like studying for an exam:\n",
        "# - Epoch 1: Read the textbook once (learn basic patterns)\n",
        "# - Epoch 2: Read again (reinforce understanding)\n",
        "# - Epoch 10: Know it well (converged)\n",
        "#\n",
        "# ============================================================\n",
        "\n",
        "def train_one_epoch(model, data_loader, criterion, optimizer, device):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch.\n",
        "\n",
        "    Args:\n",
        "        model: The neural network\n",
        "        data_loader: Provides batches of training data\n",
        "        criterion: Loss function\n",
        "        optimizer: Updates the weights\n",
        "        device: CPU or GPU\n",
        "\n",
        "    Returns:\n",
        "        Average loss for this epoch\n",
        "    \"\"\"\n",
        "    nn_model.train()  # Set model to training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_features, batch_labels in data_loader:\n",
        "        # Move data to the same device as the model\n",
        "        batch_features = batch_features.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        # STEP 1: Forward pass - get predictions\n",
        "        # üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "        # Write the code for one forward pass: make the batch features pass\n",
        "        # through the nn_model\n",
        "        outputs = ...\n",
        "\n",
        "        # STEP 2: Calculate loss\n",
        "        # üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "        # Calculate the loss\n",
        "        # Hint: use the previously defined `criterion`\n",
        "        loss = ...\n",
        "\n",
        "        # STEP 3: Backward pass - calculate gradients\n",
        "        # üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "        # Clear old gradients and calculate new gradients\n",
        "        ...\n",
        "\n",
        "        # STEP 4: Update weights\n",
        "        # üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "        # Write the code to update the weights\n",
        "        # Hint: it's a method of the optimizer\n",
        "        ...\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Return average loss per batch\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "\n",
        "def evaluate(model, data_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on a dataset (no training, just predictions).\n",
        "\n",
        "    Args:\n",
        "        model: The neural network\n",
        "        data_loader: Provides batches of test data\n",
        "        device: CPU or GPU\n",
        "\n",
        "    Returns:\n",
        "        Accuracy (0 to 1)\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode (disables dropout)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # torch.no_grad() means \"don't calculate gradients\" (faster, less memory)\n",
        "    with torch.no_grad():\n",
        "        for batch_features, batch_labels in data_loader:\n",
        "            batch_features = batch_features.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            # Get predictions\n",
        "            outputs = model(batch_features)\n",
        "\n",
        "            # Convert outputs to class predictions\n",
        "            # outputs shape: (batch_size, num_classes)\n",
        "            # We take the class with highest score as the prediction\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # Count correct predictions\n",
        "            total += batch_labels.size(0)\n",
        "            correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "print(\"‚úÖ Training functions defined!\")"
      ],
      "metadata": {
        "id": "kF4OBAU2MQZf"
      },
      "id": "kF4OBAU2MQZf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PART 7: TRAINING THE MODEL\n",
        "# ============================================================\n",
        "#\n",
        "# Now we put it all together and train for multiple epochs!\n",
        "# We'll track both loss and accuracy to see how the model improves.\n",
        "#\n",
        "# ============================================================\n",
        "\n",
        "import time\n",
        "\n",
        "# Training settings\n",
        "# üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "# Try changing this and see if the results change sensibly\n",
        "NUM_EPOCHS = 10  # How many times to go through the entire dataset\n",
        "\n",
        "# Storage for plotting\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "print(\"üöÄ Starting training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # üéØüéØüéØ - TODO - üéØüéØüéØ\n",
        "    # Call the train_one_epoch function you defined ealier with the correct parameters\n",
        "    train_loss = ...\n",
        "\n",
        "    # Evaluate on training and test sets\n",
        "    train_acc = evaluate(nn_model, train_loader, device)\n",
        "    test_acc = evaluate(nn_model, test_loader, device)\n",
        "\n",
        "    # Save for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    # Print progress every 5 epochs (or first and last)\n",
        "    if epoch == 0 or (epoch + 1) % 5 == 0 or epoch == NUM_EPOCHS - 1:\n",
        "        print(f\"Epoch [{epoch+1:2d}/{NUM_EPOCHS}] | \"\n",
        "              f\"Loss: {train_loss:.4f} | \"\n",
        "              f\"Train Acc: {train_acc*100:.1f}% | \"\n",
        "              f\"Test Acc: {test_acc*100:.1f}%\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(\"=\" * 60)\n",
        "print(f\"‚úÖ Training completed in {total_time:.1f} seconds\")\n",
        "print(f\"\\nüìä FINAL RESULTS:\")\n",
        "print(f\"   Final Training Accuracy: {train_accuracies[-1]*100:.1f}%\")\n",
        "print(f\"   Final Test Accuracy: {test_accuracies[-1]*100:.1f}%\")\n",
        "\n",
        "# Save accuracy for comparison later\n",
        "accuracy_mlp = test_accuracies[-1]"
      ],
      "metadata": {
        "id": "z5Iv_k4fMTkJ"
      },
      "id": "z5Iv_k4fMTkJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#@title PART 8: VISUALIZING TRAINING PROGRESS {display-mode: \"form\"}\n",
        "# ============================================================\n",
        "#\n",
        "#@markdown Let's see how the model improved over time!\n",
        "#\n",
        "#@markdown Good signs:\n",
        "#@markdown - Loss going DOWN over epochs\n",
        "#@markdown - Accuracy going UP over epochs\n",
        "#@markdown - Train and Test accuracy are close (no overfitting)\n",
        "#\n",
        "#@markdown Bad signs:\n",
        "#@markdown - Train accuracy is high but Test accuracy is low ‚Üí Overfitting!\n",
        "#@markdown   (Model memorized training data but doesn't generalize)\n",
        "#\n",
        "# ============================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Loss over epochs\n",
        "axes[0].plot(range(1, NUM_EPOCHS + 1), train_losses, 'b-', linewidth=2, marker='o', markersize=4)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training Loss Over Time')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Accuracy over epochs\n",
        "axes[1].plot(range(1, NUM_EPOCHS + 1), train_accuracies, 'b-', linewidth=2, marker='o', markersize=4, label='Training')\n",
        "axes[1].plot(range(1, NUM_EPOCHS + 1), test_accuracies, 'r-', linewidth=2, marker='s', markersize=4, label='Test')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].set_title('Accuracy Over Time')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].set_ylim([0, 1.05])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check for overfitting\n",
        "if train_accuracies[-1] - test_accuracies[-1] > 0.1:\n",
        "    print(\"‚ö†Ô∏è Warning: Gap between train and test accuracy is large!\")\n",
        "    print(\"   This suggests OVERFITTING - the model memorized the training data.\")\n",
        "    print(\"   Consider: more dropout, less epochs, or more training data.\")\n",
        "else:\n",
        "    print(\"‚úÖ Train and test accuracy are close - no significant overfitting!\")\n",
        "\n",
        "# 1. Get all predictions for the test set\n",
        "nn_model.eval()  # Set the model to evaluation mode\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():  # Turn off gradient calculation (saves memory)\n",
        "    for batch_features, batch_labels in test_loader:\n",
        "        # Move features to the same device as the model (CPU or GPU)\n",
        "        batch_features = batch_features.to(device)\n",
        "\n",
        "        # Ask the model for predictions\n",
        "        outputs = nn_model(batch_features)\n",
        "\n",
        "        # Convert raw scores to actual class predictions (0, 1, 2...)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Move back to CPU and convert to numpy for reporting\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(batch_labels.numpy())\n",
        "\n",
        "# 2. Convert lists to simple numpy arrays\n",
        "y_pred_mlp = np.array(all_predictions)\n",
        "y_true_mlp = np.array(all_labels)\n",
        "\n",
        "# 3. Calculate Accuracy\n",
        "accuracy_mlp = accuracy_score(y_true_mlp, y_pred_mlp)\n",
        "\n",
        "# 4. Print classification report\n",
        "print(\"üìä DETAILED RESULTS: Neural Network (MLP)\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Accuracy: {accuracy_mlp:.4f} ({accuracy_mlp*100:.1f}%)\")\n",
        "\n",
        "# Prepare role names for the report\n",
        "target_names = [id_to_role[i] for i in sorted(id_to_role.keys())]\n",
        "\n",
        "print(f\"\\nDetailed Metrics per Role:\")\n",
        "print(classification_report(y_true_mlp, y_pred_mlp, target_names=target_names))\n",
        "\n",
        "# 5. Visualize Confusion Matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_mlp = confusion_matrix(y_true_mlp, y_pred_mlp)\n",
        "\n",
        "sns.heatmap(cm_mlp, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=target_names,\n",
        "            yticklabels=target_names)\n",
        "\n",
        "plt.title('Confusion Matrix: Neural Network (MLP)')\n",
        "plt.xlabel('What the model PREDICTED')\n",
        "plt.ylabel('What it ACTUALLY was')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z1SADi9tMWZQ"
      },
      "id": "Z1SADi9tMWZQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ef81a06a-0ee3-4224-9156-e95e4286c2fb",
      "metadata": {
        "id": "ef81a06a-0ee3-4224-9156-e95e4286c2fb"
      },
      "source": [
        "## Section 2.4 - ‚öîÔ∏è Model Showdown: Selecting the Ultimate Task Assigner\n",
        "\n",
        "We have explored the data, and trained three different models for the same tasks. It‚Äôs time to choose the one that works best!\n",
        "\n",
        "In this section, we take our three trained competitors‚Äîthe **Support Vector Machine (SVM)**, the **Random Forest**, and our custom **PyTorch Neural Network**‚Äîand put them to the ultimate test using data they have never seen before (the test set).\n",
        "\n",
        "### The Scorecard: Weighted F1-Score\n",
        "To determine our winner, we are looking at the **Weighted F1-Score** (not just accuracy). This metric is crucial because:\n",
        "- It balances **Precision** (how many of the tasks assigned to a dev actually belonged to them).\n",
        "- It balances **Recall** (how many of a dev's actual tasks the model successfully found).\n",
        "- It accounts for any slight imbalances in our dataset across the 5 roles (even though our dataset should not have any).\n",
        "\n",
        "### What to Look For:\n",
        "- **Precision vs. Recall:** Does one model struggle with a specific role? (e.g., confusing \"Backend Dev\" with \"Data Scientist\").\n",
        "- **Consistency:** Does the Neural Network outperform traditional methods, or is the SVM's linear boundary enough to solve this problem?\n",
        "\n",
        "Run the cell below to see the classification reports and crown our **Project Winner**! üèÜ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compare the models and choose the best one! {display-mode: \"form\"}\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# ==========================================\n",
        "# 2. Simplified PyTorch Predictor (No Training Logic)\n",
        "# ==========================================\n",
        "class PytorchPredictor:\n",
        "    \"\"\"A minimal wrapper to handle tensor conversion for inference only.\"\"\"\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.model.eval() # Set to evaluation mode (disables Dropout)\n",
        "\n",
        "    def predict(self, X):\n",
        "        with torch.no_grad():\n",
        "            # Convert numpy to tensor\n",
        "            X_tensor = torch.FloatTensor(X)\n",
        "            outputs = self.model(X_tensor)\n",
        "            # Get the index of the highest logit (the prediction)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "        return predicted.numpy()\n",
        "\n",
        "# ==========================================\n",
        "# 3. Setup Models for Evaluation\n",
        "# ==========================================\n",
        "# Wrap your existing nn_model\n",
        "wrapped_nn = PytorchPredictor(nn_model)\n",
        "\n",
        "# Your dictionary now contains models that are ALREADY trained\n",
        "models = {\n",
        "    \"SVM (Linear)\": svm_linear,           # Must be a pre-trained SVC object\n",
        "    \"Random Forest\": rf_model,            # Must be a pre-trained RF object\n",
        "    \"Neural Network (PyTorch)\": wrapped_nn\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 4. Pure Evaluation Loop\n",
        "# ==========================================\n",
        "target_names = sorted(df['role'].unique())\n",
        "results = []\n",
        "\n",
        "print(\"üîç Running Inference on Test Dataset...\\n\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Only Predict\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    # Score\n",
        "    f1 = f1_score(y_test, preds, average='weighted')\n",
        "\n",
        "    print(f\"üìä {name}\")\n",
        "    print(f\"Weighted F1-Score: {f1:.4f}\")\n",
        "    print(classification_report(y_test, preds, target_names=target_names, zero_division=0))\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    results.append({\"Model\": name, \"F1\": f1})\n",
        "\n",
        "# Summary Table\n",
        "summary_df = pd.DataFrame(results).sort_values(by=\"F1\", ascending=False)\n",
        "print(\"\\nüèÜ Final Comparison Summary:\")\n",
        "print(summary_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "YdqhpbMTMoUm"
      },
      "id": "YdqhpbMTMoUm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üèÜ Select Your Winning Model { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Choose which model performed best in the evaluation to use for the Web App and then run this cell.\n",
        "selected_winner = \"SVM (Linear)\" #@param [\"SVM (Linear)\", \"Random Forest\", \"Neural Network (PyTorch)\"]\n",
        "\n",
        "# Map the string selection back to your actual model objects\n",
        "if selected_winner == \"SVM (Linear)\":\n",
        "    best_model = svm_linear\n",
        "elif selected_winner == \"Random Forest\":\n",
        "    best_model = rf_model\n",
        "else:\n",
        "    best_model = wrapped_nn\n",
        "\n",
        "print(f\"‚úÖ Success! 'best_model' is now set to: {selected_winner}\")"
      ],
      "metadata": {
        "id": "6PcUaaZq_PxV"
      },
      "id": "6PcUaaZq_PxV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "991e46cb-4c13-4522-bc67-1cb0785cb917",
      "metadata": {
        "id": "991e46cb-4c13-4522-bc67-1cb0785cb917"
      },
      "source": [
        "## üöÄ Section 3: The Integrated Manager App\n",
        "\n",
        "Time to integrate your classification tool in the rest of the app! By running the cell below, you will see a web app where:\n",
        "\n",
        "- You can choose among 100 different meeting transcripts\n",
        "- You can click on \"extract and assign tasks\" and:\n",
        "  -  The meeting transcripts will be split into tasks (this part is implemented for you)\n",
        "  -  **The model you have created and selected** will assign each of those tasks to one of the employees\n",
        "\n",
        "Give it a try!\n",
        "\n",
        "If you want, you can find the full application on Moodle, with instructions on how to run and deploy it. However, it is not necessary to read or interact with it for the successful completion of the project.\n",
        "\n",
        "> ‚ö†Ô∏è **Warning:**\n",
        "> Make sure that you saved your model in the `best_model` variable before running the app. To do that, you have to select the best performing model in the cell above and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1791882c-5402-43c8-ba39-1d702861e6e6",
      "metadata": {
        "id": "1791882c-5402-43c8-ba39-1d702861e6e6"
      },
      "outputs": [],
      "source": [
        "#@title Run the Web app { display-mode: \"form\" }\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "import IPython\n",
        "\n",
        "# Load the datasets from your Drive path\n",
        "DATASET_PATH = \"/content/drive/MyDrive/BMAI/week1/task_meeting/data\"\n",
        "df_meetings = pd.read_csv(f\"{DATASET_PATH}/final_transcripts_meetings.csv\")\n",
        "df_tasks = pd.read_pickle(f\"{DATASET_PATH}/employee_tasks_meeting_id.pkl\")\n",
        "\n",
        "def getMeetingMinutes(meeting_id):\n",
        "    \"\"\"\n",
        "    Fetches the transcript for a specific meeting ID.\n",
        "    Note: meeting_id comes from JS as an integer.\n",
        "    \"\"\"\n",
        "    # Filter for the specific meeting\n",
        "    meeting_row = df_meetings[df_meetings['meeting_id'] == int(meeting_id)]\n",
        "\n",
        "    if meeting_row.empty:\n",
        "        return {'error': 'Meeting not found', 'meeting_id': meeting_id}\n",
        "\n",
        "    # Return a dictionary (Colab bridge handles the conversion to JS object)\n",
        "    return meeting_row.iloc[0]['meeting_transcript']\n",
        "\n",
        "\n",
        "def assignTasks(meeting_id):\n",
        "    \"\"\"\n",
        "    Finds tasks associated with a meeting and returns structured employee assignments.\n",
        "    \"\"\"\n",
        "    # 1. Get tasks for this meeting\n",
        "    tasks_for_meeting = df_tasks[df_tasks['meeting_id'] == int(meeting_id)]\n",
        "\n",
        "    response_list = []\n",
        "\n",
        "    for _, row in tasks_for_meeting.iterrows():\n",
        "        # --- FIX 1: Reshape the embedding ---\n",
        "        # We need to turn (512,) into (1, 512) so the model sees it as a \"batch\"\n",
        "        embedding = np.array(row['task_embedding']).reshape(1, -1)\n",
        "\n",
        "        # --- FIX 2: Use the wrapper/predictor you built earlier ---\n",
        "        # This handles the torch.FloatTensor conversion and .eval() mode automatically\n",
        "        prediction_index = int(best_model.predict(embedding)[0])\n",
        "\n",
        "        task_info = {\n",
        "            \"task\": row['task_description'],\n",
        "            \"owner_id\": prediction_index,\n",
        "            \"owner_name\": id_to_role[prediction_index],\n",
        "            \"role\": row['role'],\n",
        "        }\n",
        "        response_list.append(task_info)\n",
        "\n",
        "    # Returning a list of dicts is the safest way to avoid escaping issues in Colab\n",
        "    random.shuffle(response_list)\n",
        "    return json.dumps(response_list)\n",
        "\n",
        "# Register these so JS can see them\n",
        "from google.colab import output\n",
        "output.register_callback('getMeetingMinutes', getMeetingMinutes)\n",
        "output.register_callback('assignTasks', assignTasks)\n",
        "\n",
        "# --- THE WEB INTERFACE ---\n",
        "url = f\"https://raw.githubusercontent.com/eth-bmai-fs26/project/refs/heads/{BRANCH}/week1/task_meeting/task_assigner_app_colab.html\"\n",
        "response = requests.get(url)\n",
        "response.raise_for_status() # Check for 404/500 errors\n",
        "html_app = response.text\n",
        "IPython.display.display(IPython.display.HTML(html_app))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f17d73e-2993-4ec7-8ce1-d10176eaf026",
      "metadata": {
        "id": "1f17d73e-2993-4ec7-8ce1-d10176eaf026"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}